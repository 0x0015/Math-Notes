<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head><title>Ordinary Differential Equation Notes</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='orddiff.css' rel='stylesheet' type='text/css' /> 
<meta content='orddiff.tex' name='src' /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script async='async' id='MathJax-script' src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js' type='text/javascript'></script>  
</head><body>
   <div class='maketitle'>



<h2 class='titleHead'>Ordinary Differential Equation Notes</h2>
<div class='author'><span class='cmr-12'>by 0x0015</span></div><br />
<div class='date'><span class='cmr-12'>last updated 2024-01-12</span></div>
   </div>
   <h3 class='sectionHead' id='first-order'><span class='titlemark'>1   </span> <a id='x1-10001'></a>First Order</h3>
<!-- l. 11 --><p class='noindent'><span class='paragraphHead' id='definition'><a id='x1-2000'></a><span class='cmbx-10'>Definition:</span></span>
   A differential equation is an equation with an unknown function and it’s
derivative(s)
</p>
<!-- l. 13 --><p class='indent'>   <span class='subparagraphHead' id='example-'><a id='x1-3000'></a><span class='cmbx-10'>Example 1.0.1:</span></span> \(D_xy=2x+y \) <br class='newline' />      Solution: \( y= \int 2x+7dx = x^2+7x+C \)
</p>
<!-- l. 18 --><p class='indent'>   <span class='subparagraphHead' id='example-1'><a id='x1-4000'></a><span class='cmbx-10'>Example 1.0.2:</span></span> \(D_xy+y=7 \) <br class='newline' />      Solution here is a little more complicated
</p><!-- l. 23 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='linear-first-order'><span class='titlemark'>1.1   </span> <a id='x1-50001.1'></a>Linear First Order</h4>
<!-- l. 24 --><p class='noindent'><span class='paragraphHead' id='definition1'><a id='x1-6000'></a><span class='cmbx-10'>Definition:</span></span>
   A linear first order differential equation is one such that it can be written
\(\frac {dy}{dx}+P(x)y=Q(x)\)
</p>
<!-- l. 26 --><p class='indent'>   <span class='subparagraphHead' id='example-2'><a id='x1-7000'></a><span class='cmbx-10'>Example 1.1.1:</span></span> \(D_xy=y(1-y)=y-y^2\) (the logistic model) <br class='newline' />      Solution: \(D_xy=\frac {dy}{dx}=y(1-y) \Leftrightarrow \frac {dy}{y(1-y)}=dx \Leftrightarrow \int \frac {dy}{y(1-y)}=\int dx \Leftrightarrow u=1-\frac {1}{y} \Rightarrow -\int \frac {1}{u}du = x+C \Leftrightarrow -\ln |u| = -\ln |1-\frac {1}{y}| = x+C \Leftrightarrow \ln |1-\frac {1}{y}| = -x+C \Leftrightarrow \) Assuming \(1-\frac {1}{y} \geq 0\), \(1-\frac {1}{y}=e^{-x+C} \Leftrightarrow -1=e^{-x+C}y-y=y(e^{-x+C}-1) \Leftrightarrow y=\frac {-1}{e^{-x+C}-1} \)

</p>
<!-- l. 39 --><p class='noindent'><span class='paragraphHead' id='solving-first-order-linear-des'><a id='x1-8000'></a><span class='cmbx-10'>Solving first order linear D.E.s</span></span>
   The simplest general method for solving first order linear D.E.s (\(\frac {dy}{dx}+P(x)y=Q(x)\)) is
to add an additional function \(\mu (x)\): \[ \begin {aligned} &amp; D_xy+P(x)y=Q(x) \\ &amp; \Leftrightarrow \mu (x)(D_xy+P(x)y)=D_x(\mu (x)y) \\ &amp; \Leftrightarrow \mu (x) D_xy+ \mu (x) P(x)y=\mu (x)D_xy + D_x\mu (x)y \\ &amp; \Leftrightarrow \mu (x)P(x) = D_x \mu (x)y \\ &amp; P(x)=\frac {\mu _x (x)}{\mu (x)} = \frac {d \mu }{\mu } \Rightarrow \int P(x)dx = \int \frac {d \mu }{\mu } = \ln \mu \Rightarrow \mu (x)=e^{\int P(x)dx} \end {aligned} \] And then \(\mu (x) \) can be plugged back in to find
y.
</p>
<!-- l. 53 --><p class='noindent'><span class='paragraphHead' id='theorem'><a id='x1-9000'></a><span class='cmbx-10'>Theorem:</span></span>
   If P,Q are continuous on an open interval, \(I\), containing \(x_0\), then the initial value
problem (IVP) \(\frac {dy}{dx}+P(x)y=Q(x)\), \(y(x_0)=y_0\) has a unique solution \(y(x)\) on \(I\) given by \(y(x)=e^{-\int P(x)dx} \left (\displaystyle \int e^{\int P(x)dx}Q(x)dx + C \right )\) for an appropriate
C
</p>
   <h4 class='subsectionHead' id='substitution'><span class='titlemark'>1.2   </span> <a id='x1-100001.2'></a>Substitution</h4>
<!-- l. 56 --><p class='noindent'>If you have \(\frac {dy}{dx} = f(x,y)\), substitute part of the e.q. with \(v=\alpha (x,y)\), and then plug back into the e.q. at the
end.
</p>
<!-- l. 57 --><p class='indent'>   <span class='subparagraphHead' id=''><a id='x1-11000'></a></span> Usually you want to get a linear D.E. relative to \(v\) and \(D_x v\) (for example \(D_x v + P(x)v = Q(x)\) ) which is
easier to solve.
</p>
<!-- l. 59 --><p class='indent'>   <span class='subparagraphHead' id='note-'><a id='x1-12000'></a><span class='cmbx-10'>Note 1:</span></span> sometimes a second order D.E. can be reduced into a first order by
substituting \(v=q(D_x y) \Rightarrow D_x v=w(D_x^2 y)\). (e.g. \(x D_x^2 y + D_xy = Q(x)\) sub \(v= D_x y \Rightarrow D_x v = D_x^2 y \Rightarrow x D_x v + v = Q(x)\) is 1st order)
</p>
<!-- l. 61 --><p class='indent'>   <span class='subparagraphHead' id='node-'><a id='x1-13000'></a><span class='cmbx-10'>Node 2:</span></span> you can substitute implicitly (e.g. \(y D_x y + (D_x^2 y)^2=0\) sub \(v=y D_x y \Rightarrow D_x v = (D_x y) ^2 + y D_x^2 y \Rightarrow D_x v = 0 \Rightarrow y D_x y = y \frac {dy}{dx}=v=c \Rightarrow \int ydy= \int cdx + C\))
</p><!-- l. 64 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='special-cases-of-substitution'><span class='titlemark'>1.2.1   </span> <a id='x1-140001.2.1'></a>Special cases of substitution</h5>
<!-- l. 65 --><p class='noindent'><span class='paragraphHead' id='homogenious-equation'><a id='x1-15000'></a><span class='cmbx-10'>homogenious equation:</span></span>
   An equation of the type: \(D_x y=F(\frac {y}{x})\) \(\Rightarrow \) substitute \(v=\frac {y}{x} \Rightarrow y=vx \Rightarrow D_x y=D_x(v)x+v\) which can be solved by \(v`x+v=F(v) \Rightarrow \frac {D_x v}{F(v)-v} = \frac {1}{x}\)
</p>
<!-- l. 67 --><p class='indent'>   <span class='subparagraphHead' id='1'><a id='x1-16000'></a></span> In general \(f(x,y)dy=g(x,y)dx\) substitute \(y=ux \Rightarrow \frac {dx}{x} = h(u)du \Rightarrow \) integrate.
</p>
<!-- l. 69 --><p class='noindent'><span class='paragraphHead' id='bernoulli-euquation'><a id='x1-17000'></a><span class='cmbx-10'>Bernoulli euquation:</span></span>
   An equation of the type: \(D_x y+P(x)y=Q(x)y^n\) \(\Rightarrow \) substitute \(v=y^{1-n} \Rightarrow D_x v=(1-n)y^{-n} D_xy \Rightarrow D_x v+(1-n)P(x)v=(1-n)Q(x)\)

</p>
<!-- l. 71 --><p class='indent'>   <span class='subparagraphHead' id='2'><a id='x1-18000'></a></span> Remember that n can be negative (for example \(D_x y+P(x)y=Q(x)\frac {1}{y}\))
</p><!-- l. 74 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='exact-equation'><span class='titlemark'>1.3   </span> <a id='x1-190001.3'></a>Exact equation</h4>
<!-- l. 75 --><p class='noindent'>An equation \(I(x,y)+J(x,y)D_x y=0 \Leftrightarrow I(x,y)dx+J(x,y)dy=0\) is exact iff \(I_y=J_x\). Then \(\exists \psi (x,y)\) s.t. \[ \begin {aligned} &amp; \psi _x (x,y)=I(x,y) \\ &amp; \psi _y (x,y)=J(x,y) \end {aligned} \] and \(\psi (x,y)=c\) is a solution.
</p>
<!-- l. 83 --><p class='indent'>   <span class='subparagraphHead' id='3'><a id='x1-20000'></a></span> For an IVP, given \(f(a)=b\), plugin \(x=a,y=b\) into \(\psi \), and solve for \(c\).
</p>
   <h5 class='subsubsectionHead' id='autonomous-equation'><span class='titlemark'>1.3.1   </span> <a id='x1-210001.3.1'></a>Autonomous equation</h5>
<!-- l. 86 --><p class='noindent'>An autonomous DE is one such that the independent variable (e.g. \(x\), \(t\)) is not in the
eq. (e.g. \(D_x y=P(y)\)).
</p>
<!-- l. 87 --><p class='indent'>   <span class='subparagraphHead' id='4'><a id='x1-22000'></a></span> An autonomous equation is always seperable
</p><!-- l. 90 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='seperable-equation'><span class='titlemark'>1.4   </span> <a id='x1-230001.4'></a>Seperable equation</h4>
<!-- l. 91 --><p class='noindent'>A seperable equation is one of the form \(D_x y = f(x)g(y)\). A seperable equation can be solved as
follows: \(D_x y= \frac {dy}{dx} = f(x)g(y) \Rightarrow \int \frac {dy}{g(y)} = \int f(x)dx + C \).
</p><!-- l. 93 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='second-order'><span class='titlemark'>2   </span> <a id='x1-240002'></a>Second Order</h3>
<!-- l. 94 --><p class='noindent'>A second order differential equation is a differential equation that includes the second
derivative.
</p>
   <h4 class='subsectionHead' id='second-order-constant-coefficient-homogeneous'><span class='titlemark'>2.1   </span> <a id='x1-250002.1'></a>Second Order Constant Coefficient Homogeneous</h4>
<!-- l. 96 --><p class='noindent'>A second order constant coefficient homogeneous D.E. is one with the form
\(a D_x^2 y + b D_x y + cy=0\).

</p>
<!-- l. 97 --><p class='noindent'><span class='paragraphHead' id='theorem-super-position'><a id='x1-26000'></a><span class='cmbx-10'>Theorem (Super Position):</span></span>
   If a second order homogeneous D.E. has 2 solutions \(a,b\), then \(a+b\) is also a solution.
<br class='newline' /><br class='newline' />To solve a second order linear constant coefficient homogeneous differential equation \(a D_x^2 y + b D_x y + cy=0\)
let \(y=e^{rx}\). Then by plugging in we get: \[ \begin {aligned} &amp; a(r^2e^{rx}) + b(re^{rx}) + ce^{rx} = 0 \\ &amp; \Leftrightarrow e^{rx}(ar^2 + br + c) = 0 \\ &amp; \Leftrightarrow ar^2 + br + c=0 \end {aligned} \] which can be solved for \(r=r_1,r_2\) \(\Rightarrow \) \(y=Ae^{rx} + Be^{rx}\) \(\forall A,B\) by super position. If
there is a repeated root (\(r_1=r_2\)), than let \(y=Ae^{rx}+Bxe^{rx}\), plug in, and solve.
</p><!-- l. 111 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='second-order-nonhomogeneous'><span class='titlemark'>2.2   </span> <a id='x1-270002.2'></a>Second Order Non-Homogeneous</h4>
<!-- l. 112 --><p class='noindent'>Let \(D_x^2 y + p(x) D_x y + q(x)y = g(x)\) be the 2nd order non-homogeneous D.E. For simplicity, let \(L[y]= D_x^2 y + p(x) D_x y + q(x)y\) (so the D.E. is \(L[y] = g(x)\) ).
Then the solution is of the form \(y=(c_1 y_1 + c_2 y_2 = y_h) + y_p\) where \(y_h\) is the solution to \(L[y]=0\). To find \(y_p\) there is really
two methods:
</p><!-- l. 114 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='undetermined-coefficients'><span class='titlemark'>2.2.1   </span> <a id='x1-280002.2.1'></a>Undetermined Coefficients</h5>
<!-- l. 115 --><p class='noindent'>Refer to the following table to find the general equation for \(y_p\) based on \(g(x)\):
</p>
   <div class='table'>

<!-- l. 117 --><p class='indent'>   </p><figure class='float'>

<div class='tabular'> <table class='tabular' id='TBL-2'><colgroup id='TBL-2-1g'><col id='TBL-2-1' /></colgroup><colgroup id='TBL-2-2g'><col id='TBL-2-2' /></colgroup><tr id='TBL-2-1-' style='vertical-align:baseline;'><td class='td11' id='TBL-2-1-1' style='white-space:nowrap; text-align:left;'>\(g(x)\)</td><td class='td11' id='TBL-2-1-2' style='white-space:nowrap; text-align:left;'>\(y_p\)</td></tr><tr class='hline'><td></td><td></td></tr><tr id='TBL-2-2-' style='vertical-align:baseline;'><td class='td11' id='TBL-2-2-1' style='white-space:nowrap; text-align:left;'>\(P_n(x)\) </td><td class='td11' id='TBL-2-2-2' style='white-space:nowrap; text-align:left;'>\(t^s Q_n(x)\)</td>
</tr><tr id='TBL-2-3-' style='vertical-align:baseline;'><td class='td11' id='TBL-2-3-1' style='white-space:nowrap; text-align:left;'>\(P_n(x) e^{\alpha x}\) </td><td class='td11' id='TBL-2-3-2' style='white-space:nowrap; text-align:left;'>\(t^s Q_n(x) e^{\alpha x}\)</td>
</tr><tr id='TBL-2-4-' style='vertical-align:baseline;'><td class='td11' id='TBL-2-4-1' style='white-space:nowrap; text-align:left;'>\(P_n(x) e^{\alpha x} (\sin \beta t + \cos \beta t)\) </td><td class='td11' id='TBL-2-4-2' style='white-space:nowrap; text-align:left;'>\(t^s e^{\alpha x} (Q_n(x) \sin \beta x + R_n(x) \cos \beta x) \)</td>
</tr><tr class='hline'><td></td><td></td></tr></table>                                                               </div>

   </figure>
   </div>
<!-- l. 126 --><p class='indent'>   Where \(s\) is the smallest integer \(\ge 0\) s.t. \(y_p\) is not a solution to \(L[y] = 0\) and \(P_n(x), Q_n(x), R_n(x)\) are polynomials of
degree n. <br class='newline' /><br class='newline' />Then plug into \(L[y_p]=g(t)\) and solve for the coefficients.
</p>
   <h5 class='subsubsectionHead' id='variation-of-parameters'><span class='titlemark'>2.2.2   </span> <a id='x1-290002.2.2'></a>Variation of Parameters</h5>
<!-- l. 131 --><p class='noindent'>Given \(y_h=c_1 y_1 + c_2 y_2\) we wantto find \(u_1, u_2\) s.t. \(D_x(u_1)y_1 + D_x(u_2)y_2 = 0\) and \(D_x(u_1)D_x(y_1)+ D_x(u_2)D_x(y_2)= g(x)\). We can find precise values using the Wronskian.
</p>
<!-- l. 133 --><p class='noindent'><span class='paragraphHead' id='definition2'><a id='x1-30000'></a><span class='cmbx-10'>Definition:</span></span>
   The Wronskian of two functions \(w(f,g)\) is defined as \(w(f,g) := \begin {vmatrix} f &amp; g \\ D_x f &amp; D_x g \end {vmatrix}\)
</p>
<!-- l. 135 --><p class='indent'>   <span class='subparagraphHead' id='lemma'><a id='x1-31000'></a><span class='cmbx-10'>Lemma:</span></span> If \(w(f,g) \equiv 0\) (\(w(f,g)(x)=0, \forall x\)), then \(f,g\) are linearally dependent. If \(w(f,g) \not \equiv 0\) (\(\exists x\) s.t. \(w(f,g)(x) \neq 0\)), then \(f,g\) are linearally
independent.
</p>
<!-- l. 138 --><p class='noindent'><span class='paragraphHead' id='5'><a id='x1-32000'></a></span>
   Then \(D_x u_1 = \frac {-y_2 g}{w(y_1, y_2)}\) and \(D_x u_2 = \frac {y_1 g}{w(y_1, y_2)}\). This tells us that \(y_p = u_1 y_1 + u_2 y_2\) (notice that \(u_1, u_2\) are not derivatives).
</p>
<!-- l. 141 --><p class='noindent'><span class='paragraphHead' id='6'><a id='x1-33000'></a></span>
   Equivelently, this is: \[ \begin {aligned} y_p &amp; = -y_1(x) \int _{x_0}^x \frac {y_2 (s) g(s)}{w(y_1, y_2)(s)} ds + y_2(x) \int _{x_0}^x \frac {y_1 (s) g(s)}{w(y_1, y_2)(s)} ds \\ &amp; = \int _{x_0}^x \frac {y_2(x)y_1(s)-y_1(x)y_2(s)}{w(y_1,y_2)(s)} g(s) ds = 0 \end {aligned} \] Where \(x_0\) is a convenient point int the interval \(I\) in which \(y_1, y_2\) are
defined.
</p><!-- l. 151 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='nth-order'><span class='titlemark'>3   </span> <a id='x1-340003'></a>\(N\)th Order</h3>
<!-- l. 152 --><p class='noindent'>A \(n\)th order differential equation is (as the name implies), a differential equation that
includes derrivatives of \(n\) orders.
</p>
   <h4 class='subsectionHead' id='nth-order-constant-coefficient-homogeneuous'><span class='titlemark'>3.1   </span> <a id='x1-350003.1'></a>\(N\)th Order Constant Coefficient Homogeneuous</h4>
<!-- l. 154 --><p class='noindent'>A \(n\)th order constant coefficient homogeneous D.E. is one with the form \(a_0 D_x^n y + a_1 D_x^{n-1} y + \cdots + a_{n-1} D_x y + a_n y=0\).

</p>
<!-- l. 156 --><p class='noindent'><span class='paragraphHead' id='7'><a id='x1-36000'></a></span>
   To solve, by following the same procedure as for the 2nd order parallel, let \(y=e^{rx} \Rightarrow a_0r^n + a_1r^{n-1} + \cdots + a_{n-1}r + a_n = 0\), and
solve.
</p><!-- l. 159 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='systems-of-differential-equations'><span class='titlemark'>4   </span> <a id='x1-370004'></a>Systems of Differential Equations</h3>
<!-- l. 160 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='first-order1'><span class='titlemark'>4.1   </span> <a id='x1-380004.1'></a>First Order</h4>
<!-- l. 161 --><p class='noindent'><span class='paragraphHead' id='definition3'><a id='x1-39000'></a><span class='cmbx-10'>Definition:</span></span>
   A system of first order differential equations is defined as such: \(D_t x_i = \sum \limits _{j=1}^n (P_{ij} (t) x_j) + g_i (t)\) for \(1 \le i \le n\) \(\Leftrightarrow \)
\(D_t \vec {x} = \begin {bmatrix} P_{ij} (t) \end {bmatrix}_{ij} \vec {x} = \begin {bmatrix} g_1(t) \\ \vdots \\ g_n(t) \end {bmatrix} \)
</p>
<!-- l. 164 --><p class='indent'>   <span class='subparagraphHead' id='8'><a id='x1-40000'></a></span> A system of first order D.E.s is homogeneous if \(g_i(t)=0, \forall t\).
</p>
<!-- l. 167 --><p class='noindent'><span class='paragraphHead' id='theorem1'><a id='x1-41000'></a><span class='cmbx-10'>Theorem:</span></span>
   If \(\{\vec {e_i}\}\) is a standard basis for \(\Re ^n\), \(\vec {x_i}\) is a solution to the homogeneous system with the
initial condidtion \(\vec {x_i} (t_0) = \vec {e_i}\) then \(\{\vec {x_i}\}\) is the fundimental solution set.
</p><!-- l. 170 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='eigenvalue-method-for-homogeneous-systems'><span class='titlemark'>4.1.1   </span> <a id='x1-420004.1.1'></a>Eigenvalue Method for Homogeneous Systems</h5>
<!-- l. 171 --><p class='noindent'>For a homogeneous system, you have \(D_x \vec {x}=A \vec {x} \). If you can find the eigenvalues \(\lambda _1, \cdots , \lambda _n\) and
eigenvectors \(\vec {v_1}, \cdots , \vec {v_n}\), then \(\vec {x}= \sum \limits _{i=1}^n c_i e^{\lambda _i} \vec {v_i} \)
</p><!-- l. 173 --><p class='indent'>   If there are repeated eigenvalues, solve for the known one like normal: (In this
example I’m just showing for a system of two, but it extends) \(\vec {x}=\vec {x_1} + \vec {x_2}\), \(\vec {x_1}=c_1 \vec {v_1} e^{\lambda _1 t} \), let \(\vec {x_2}=\vec {w} t e^t \Rightarrow D_t \vec {x_2} = \vec {w} (e^t + te^t)\). Then plug back
into initial D.E., and solve for \(\vec {w}\).

</p><!-- l. 175 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='converting-to-and-from-systems'><span class='titlemark'>4.1.2   </span> <a id='x1-430004.1.2'></a>Converting to and from systems</h5>
<!-- l. 176 --><p class='noindent'>Given a second order, often you can convert to a system of first orders, or vice versa.
This is done by assigning the variables in the system to be different level
derivatives.
</p>
<!-- l. 177 --><p class='noindent'><span class='paragraphHead' id='example-3'><a id='x1-44000'></a><span class='cmbx-10'>Example 4.1.2.1:</span></span>
   \(a D_x^2 x + bx = 0 \Rightarrow \) let \(x_1=x, x_2=D_x x \Rightarrow D_x x_2 = \frac {-b x_1}{a}, D_x x_1 = x_2\)
</p>
<!-- l. 179 --><p class='noindent'><span class='paragraphHead' id='9'><a id='x1-45000'></a></span>
   You can also go from multiple of a higher order to lower orders:
</p>
<!-- l. 181 --><p class='noindent'><span class='paragraphHead' id='example-4'><a id='x1-46000'></a><span class='cmbx-10'>Example 4.1.2.2:</span></span>
   For two second orders we define \(y_1=x_1,\) \(y_2=D_x x_1,\) \(y_3 = x_2,\) \(y_4 = D_x x_2\)
</p><!-- l. 184 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='matrix-exponents'><span class='titlemark'>4.1.3   </span> <a id='x1-470004.1.3'></a>Matrix Exponents</h5>
<!-- l. 185 --><p class='noindent'>Consider \(D_t X = AX\) \(\forall X \in M_{n \times n}(S)\). If \(\vec {x} = c_1 \vec {x_1} + c_2 \vec {x_2} + \cdots + c_n \vec {x_n}\) (means \(\vec {x_i}=\vec {v_i}e^{\lambda _i t}\) most likely) is a solution to \(D_t \vec {x} = A \vec {x}\), then there is a solution \(X=\Phi (t)=\begin {bmatrix} \vec {x_1} &amp; \vec {x_2} &amp; \cdots &amp; \vec {x_n} \end {bmatrix}\)
where \(\vec {x_i}\) are the columns of the matrix. If there is an initial condition \(\vec {x} (0) = \vec {x_0}\) then
\(\Phi (t) \vec {c} = \vec {x_0} \Leftrightarrow \vec {c} = \Phi ^ {-1} (t) \vec {x}\)
</p>
<!-- l. 186 --><p class='noindent'><span class='paragraphHead' id='10'><a id='x1-48000'></a></span>
   Then  to  solve  \(D_t X = AX,\)  \(\vec {x}(0) = \vec {x_0}\),  we  have  \(\vec {x}(t) = \Phi (t) \Phi ^{-1}(0) \vec {x_0}\)
To solve \(D_t X = AX\), we really want \(X=e^{At}\). We know \(e^x = \sum \limits _{n=0}^{\infty } \frac {x^n}{n!} \Rightarrow e^A = \sum \limits _{n=0}^{\infty } \frac {A^n}{n!} \Rightarrow e^{At} = \sum \limits _{n=0}^{\infty } \frac {A^n t^n}{n!}\)
</p>
<!-- l. 190 --><p class='noindent'><span class='paragraphHead' id='note-1'><a id='x1-49000'></a><span class='cmbx-10'>Note 4.1.3.1:</span></span>
   If  \(AB=BA\),  \(e^{A+B}=e^A e^B; (e^A)^{-1} = e^{-A}; e^{0 \in M_{n \times n} (S)} = I\)
If  \(A=diag(a_1, a_2, \cdots , a_n)\)  then  \(e^A=diag(e^{a_1}, e^{a_2}, \cdots , e^{a_n})\)
If  \(A=SDS^{-1}\)  for  a  diagonal  \(D\)  then  \(e^A=S e^D S^{-1}\).
if \(A\) is non-diagonalizable, then cehck if there is \(n\) s.t. \(A^n=0\). If so, than a polynomial can be
constructed from \(e^A=\sum \limits _{i=0}^n \frac {A^i}{i!}\) \(\left (=\sum \limits _{n=0}^{\infty } \frac {A^n}{n!}\right )\)
</p>
<!-- l. 198 --><p class='noindent'><span class='paragraphHead' id='example-5'><a id='x1-50000'></a><span class='cmbx-10'>Example 4.1.3.2</span></span>
   For \(A=\begin {bmatrix}0&amp;1&amp;2 \\ 0&amp;0&amp;3 \\ 0&amp;0&amp;0 \end {bmatrix}\), \(A^2 \neq 0\), \(A^3=0 \Rightarrow e^A=\sum \limits _{i=0}^2 \frac {A^i}{i!}=(A^0=I)+A+\frac {1}{2}A^2\)

</p>
<!-- l. 200 --><p class='noindent'><span class='paragraphHead' id='note-2'><a id='x1-51000'></a><span class='cmbx-10'>Note 4.1.3.3:</span></span>
   If \(AB=BA\), \(C=A+B\) then \(e^{Ct}=e^{At}e^{Bt}\). Note that if \(A=nI\), \(AB=nIB=nB=Bn=BnI=BA\).
</p>
<!-- l. 202 --><p class='noindent'><span class='paragraphHead' id='11'><a id='x1-52000'></a></span>
   Thus the solution to \(D_t \vec {x}=a \vec {x},\) \(\vec {x}(0) = \vec {x_0}\) is \(\vec {x}(t)=e^{At} \vec {x_0 }\) \((=\Phi (t) \Phi ^{-1} (0) \vec {x_0} \Rightarrow e^{At} = \Phi (t) \Phi ^{-1} (0) \vec {x_0} )\)
</p>
    
</body> 
</html>